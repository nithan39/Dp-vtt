    # --- after preprocessing and initial shape handling ---
    # ensure input_data is numpy uint8
    input_data = np.asarray(input_data, dtype=np.uint8)

    # ensure batch dim exists
    if input_data.ndim == 3:
        # H,W,C  -> add batch
        input_data = np.expand_dims(input_data, axis=0)

    # Desired per-frame shape (H,W,C)
    if len(input_shape) == 4:   # network shape is (N,H,W,C)
        H, W, C = input_shape[1], input_shape[2], input_shape[3]
    elif len(input_shape) == 3: # network shape is (H,W,C)
        H, W, C = input_shape[0], input_shape[1], input_shape[2]
    else:
        raise RuntimeError(f"Unsupported input_shape: {input_shape}")

    # If data shape doesn't match (N,H,W,C), try common permutations
    n, h, w, c = input_data.shape
    if (h, w, c) != (H, W, C):
        # maybe data is N,C,H,W -> transpose
        if (h, w, c) == (C, H, W):
            input_data = np.transpose(input_data, (0, 2, 3, 1))
            n, h, w, c = input_data.shape
            print("[INFO] Transposed NCHW -> NHWC")
        # maybe data is N, H, C (rare) or other mismatch - try more attempts:
        elif (h, w, c) == (H, C, W):
            input_data = np.transpose(input_data, (0, 1, 3, 2))
            n, h, w, c = input_data.shape
            print("[INFO] Minor transpose applied")
        else:
            # Print diagnostics and raise so we don't send wrong-sized buffer
            print(f"[ERROR] Input data shape after attempts: {input_data.shape}; expected per-frame (H,W,C)=({H},{W},{C})")
            raise RuntimeError("Input data layout doesn't match model input. See diagnostic print above.")

    # compute expected elements per frame and frames
    elems_per_frame = H * W * C

    # The input vstream may have a specific frame_count/size. Try to infer:
    expected_frame_count = 1
    if hasattr(input_info, "frame_count") and input_info.frame_count:
        expected_frame_count = int(input_info.frame_count)
    elif hasattr(input_info, "size") and input_info.size:
        # input_info.size is bytes for vstream; compute frames if possible
        # size is total bytes, elems_per_frame elements => frames = size / elems_per_frame
        expected_frame_count = int(input_info.size // elems_per_frame)

    # If python-side batch != expected_frame_count, repeat the frames properly
    if input_data.shape[0] != expected_frame_count:
        if input_data.shape[0] == 1:
            input_data = np.repeat(input_data, expected_frame_count, axis=0)
            print(f"[INFO] Repeated single image to match expected_frame_count={expected_frame_count}")
        else:
            # tile/truncate to match expected_frame_count
            if input_data.shape[0] < expected_frame_count:
                reps = int(np.ceil(expected_frame_count / input_data.shape[0]))
                input_data = np.repeat(input_data, reps, axis=0)[:expected_frame_count]
            else:
                input_data = input_data[:expected_frame_count]

    # Make memory contiguous and correct dtype
    input_data = np.ascontiguousarray(input_data, dtype=np.uint8)

    # Final sanity check
    final_size = input_data.size  # total elements across batch
    expected_total = expected_frame_count * elems_per_frame
    print(f"[DEBUG] final input shape: {input_data.shape}, dtype: {input_data.dtype}, elements: {final_size}; expected elements: {expected_total}")
    if final_size != expected_total:
        raise RuntimeError(f"Final buffer element count mismatch: expected {expected_total} got {final_size}")

    # Build the dictionary correctly (use input_data)
    if isinstance(self.input_vstreams_params, dict):
        input_name = list(self.input_vstreams_params.keys())[0]
    else:
        param = self.input_vstreams_params[0]
        input_name = getattr(param, "name", param)

    input_dict = {input_name: input_data}
